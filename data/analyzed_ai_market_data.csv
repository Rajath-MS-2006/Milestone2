platform,timestamp,query,text,label,score,url
newsapi,2025-10-15 13:44:46+00:00,artificial intelligence,Coinbase ups CoinDCX bet; Prosus picks Ixigo stake Coinbase is increasing its investment in the Indian cryptocurrency exchange CoinDCX. This and more in today's ETtech Top 5.Also in the letter: Apple eyes tax tweakOpenAI's sparks market surgeAmazon's… [+6769 chars],neutral,0.0,https://economictimes.indiatimes.com/tech/newsletters/tech-top-5/coinbase-ups-coindcx-bet-prosus-picks-ixigo-stake/articleshow/124581145.cms
newsapi,2025-10-15 13:44:46+00:00,artificial intelligence,Coinbase ups CoinDCX stake; Prosus' Ixigo investment 2.0 Coinbase is increasing its investment in the Indian cryptocurrency exchange CoinDCX. This and more in today's ETtech Top 5.Also in the letter: Apple eyes tax tweakOpenAI's sparks market surgeAmazon's… [+6700 chars],neutral,0.0,https://economictimes.indiatimes.com/tech/newsletters/tech-top-5/coinbase-ups-coindcx-stake-prosus-ixigo-investment-2-0/articleshow/124581145.cms
newsapi,2025-10-15 13:41:53+00:00,artificial intelligence,"Self-learning AI reveals NFL against the spread, over/under and money-line picks for every Week 7, 2025 game The AFC West race heats up in Week 7 with several key battles, including a matchup between longtime bitter rivals when the Kansas City Chiefs take on the Las Vegas Raiders at Kansas City. The Chiefs … [+3543 chars]",neutral,0.0,https://www.cbssports.com/nfl/news/nfl-picks-against-spread-money-line-over-under-ai-week-7-betting-predictions/
newsapi,2025-10-15 13:39:33+00:00,artificial intelligence,"Rakuten Considers US IPO for Credit Card Business Rakuten is reportedly considering an American initial public offering (IPO) for its credit card business.The Japanese eCommerce/finance conglomerate began weighing the IPO last month, Reuters reporte… [+2267 chars]",neutral,0.0,http://www.pymnts.com/news/ipo/2025/rakuten-considers-us-ipo-for-credit-card-business/
newsapi,2025-10-15 13:37:48+00:00,artificial intelligence,"Groups including BlackRock, Microsoft, Nvidia, and xAI join forces to acquire Aligned Data Centers — $40B deal delivers 5GW of operational and planned data center capacity Asset management firm BlackRock has joined forces with Microsoft, Nvidia, and xAI to purchase Aligned Data Centers (Aligned) through an investment consortium called the Artificial Intelligence Infras… [+2503 chars]",positive,0.6,https://www.tomshardware.com/tech-industry/artificial-intelligence/groups-including-blackrock-microsoft-nvidia-and-xai-join-forces-to-acquire-aligned-data-centers-usd40b-deal-delivers-5gw-of-operational-and-planned-data-center-capacity
newsapi,2025-10-15 13:37:41+00:00,artificial intelligence,"When it comes to private credit on Wall Street, one firm's win is another's fear Hello there! If you're looking to get more intimate with ChatGPT, you're in luck. Sam Altman said OpenAI's chatbot will allow ""erotica for verified adults ."" In today's big story, BlackRock's Larry… [+6832 chars]",neutral,0.0,https://www.businessinsider.com/blackrock-jpmorgan-earnings-private-credit-debate-risks-benefits-2025-10
newsapi,2025-10-15 13:35:51+00:00,artificial intelligence,"Group including Nvidia, BlackRock buying Aligned Data Centers in deal worth about $40 billion A group including BlackRock, Nvidia and Microsoft is buying Aligned Data Centers in an approximately $40 billion deal in an effort to expand next-generation cloud and artificial intelligence infrastr… [+2107 chars]",positive,0.6,https://www.seattlepi.com/business/article/group-including-nvidia-blackrock-buying-aligned-21101820.php
newsapi,2025-10-15 13:35:36+00:00,artificial intelligence,Will You Be Comfortable Buying Nvidia Stock? Do you already hold Nvidia stock? You may want to think about retaining it. Are you planning to buy in? This could be your opportunity. Nvidia has emerged the most important semiconductor player in t… [+4544 chars],positive,0.5,https://www.forbes.com/sites/greatspeculations/2025/10/15/will-you-be-comfortable-buying-nvidia-stock/
newsapi,2025-10-15 13:35:00+00:00,artificial intelligence,"Self-Drive Car Rental Market Report 2025-2030, with Profiles of SIXT Rent a Car, Enterprise Mobility, Hertz, Turo, Avis, Zoomcar, CarDekho, Europcar, Fox Rent A Car, and Budget Rent A Car System Dublin, Oct. 15, 2025 (GLOBE NEWSWIRE) -- The ""Self-Drive Car Rental Market - Forecasts from 2025 to 2030"" report has been added to ResearchAndMarkets.com's offering. The Self-Drive Car Rental Marke… [+7606 chars]",neutral,0.0,https://www.globenewswire.com/news-release/2025/10/15/3167206/28124/en/Self-Drive-Car-Rental-Market-Report-2025-2030-with-Profiles-of-SIXT-Rent-a-Car-Enterprise-Mobility-Hertz-Turo-Avis-Zoomcar-CarDekho-Europcar-Fox-Rent-A-Car-and-Budget-Rent-A-Car-Sy.html
newsapi,2025-10-15 13:34:04+00:00,artificial intelligence,"Group including Nvidia, BlackRock buying Aligned Data Centers in deal worth about $40 billion A group including BlackRock, Nvidia and Microsoft is buying Aligned Data Centers in an approximately $40 billion deal in an effort to expand next-generation cloud and artificial intelligence infrastr… [+148 chars]",positive,0.6,https://biztoc.com/x/0859a6ef9df79b9a
newsapi,2025-10-15 13:34:00+00:00,artificial intelligence,"Slam dunk without basketball: Pep Guardiola is Spain’s Tiger Woods Pep Guardiola has always represented world-class football, both as a player and as a current coach. But the Spaniard also knows how to impress on a different kind of green field. During a relaxed ro… [+504 chars]",positive,0.7,https://onefootball.com/en/news/slam-dunk-without-basketball-pep-guardiola-is-spains-tiger-woods-41808634
newsapi,2025-10-15 13:33:42+00:00,artificial intelligence,"Dubai tech conference Gitex is all about AI One of the worlds biggest tech conferences is, unsurprisingly, all about AI.At GITEX Global in Dubai this week, thousands of exhibitors and startups are showcasing chips and software designed to fulf… [+142 chars]",neutral,0.1,https://biztoc.com/x/082009cf46e2ecd0
newsapi,2025-10-15 13:31:35+00:00,artificial intelligence,"Google to build $15 billion AI hub in India Google has said it will set up a $15 billion artificial intelligence hub in India, its largest investment in the country. Google Cloud CEO Thomas Kurian said in a blog on Tuesday that the investment… [+1662 chars]",positive,0.8,https://www.rt.com/india/626475-google-ai-hub-india/
newsapi,2025-10-15 13:30:09+00:00,artificial intelligence,"5 stories you must read today, October 15: From SC allowing green firecrackers in Delhi-NCR to Kerala school hijab controversy and more <li>01SC allows green firecrackers in Delhi-NCR during Diwali The Supreme Court on Wednesday allowed the sale and bursting of green firecrackers in Delhi-NCR during upcoming Diwali celebrations. The… [+3086 chars]",neutral,0.0,https://indianexpress.com/article/india/5-stories-you-must-read-today-october-15-sc-allowing-green-firecrackers-delhi-ncr-kerala-school-hijab-10308716/
newsapi,2025-10-15 13:30:00+00:00,artificial intelligence,"Taste Modulators Market Size Exceed to USD 3,151.84 Million by 2034, Driven by Health-Conscious Consumers and Technological Innovations Ottawa, Oct. 15, 2025 (GLOBE NEWSWIRE) -- The global taste modulators market size stood at USD 1,558 million in 2024 and is anticipated to increase from USD 1,671.73 million in 2025 to reach USD 3,15… [+25538 chars]",positive,0.7,https://www.globenewswire.com/news-release/2025/10/15/3167201/0/en/Taste-Modulators-Market-Size-Exceed-to-USD-3-151-84-Million-by-2034-Driven-by-Health-Conscious-Consumers-and-Technological-Innovations.html
newsapi,2025-10-15 13:27:05+00:00,artificial intelligence,"BlackRock’s GIP Buys Aligned Data Centers in $40 Billion Bet Hyperscale Centers Aligneds business is focused on hyperscale centers in the Americas, positioning it to benefit from that demand at a time when the Trump administration has been pushing for tech fi… [+4090 chars]",neutral,0.2,https://financialpost.com/pmn/business-pmn/blackrocks-gip-buys-aligned-data-centers-in-40-billion-bet
newsapi,2025-10-15 13:23:24+00:00,artificial intelligence,"Group including Nvidia, BlackRock buying Aligned Data Centers in deal worth about $40 billion A group including BlackRock, Nvidia and Microsoft is buying Aligned Data Centers in an approximately $40 billion deal in an effort to expand next-generation cloud and artificial intelligence infrastr… [+1963 chars]",positive,0.8,https://finance.yahoo.com/news/group-including-nvidia-blackrock-buying-132324589.html
newsapi,2025-10-15 13:23:24+00:00,artificial intelligence,"Group including Nvidia, BlackRock buying Aligned Data Centers in deal worth about $40 billion A group including BlackRock, Nvidia and Microsoft is buying Aligned Data Centers in an approximately $40 billion deal in an effort to expand next-generation cloud and artificial intelligence infrastr… [+1963 chars]",positive,0.8,https://finance.yahoo.com/news/group-including-nvidia-blackrock-buying-132324494.html
newsapi,2025-10-15 13:23:24+00:00,artificial intelligence,"Group including Nvidia, BlackRock buying Aligned Data Centers in deal worth about $40 billion A group including BlackRock, Nvidia and Microsoft is buying Aligned Data Centers in an approximately $40 billion deal in an effort to expand next-generation cloud and artificial intelligence infrastr… [+2460 chars]",positive,0.8,https://www.wsbtv.com/news/business/group-including/LP6LAGBAQM2XNJQG3A7OLJFOXE/
newsapi,2025-10-15 13:19:00+00:00,artificial intelligence,"BluSky AI Inc. to Update Investors on the Emerging Growth Conference on October 22, 2025 Salt Lake City Utah, Oct. 15, 2025 (GLOBE NEWSWIRE) -- BluSky AI Inc. (OTCID: BSAI), (BluSky AI or the Company), headquartered in Salt Lake City, Utah, will be the Neocloud of the future, purpose-bui… [+3812 chars]",neutral,0.1,https://www.globenewswire.com/news-release/2025/10/15/3167187/29006/en/BluSky-AI-Inc-to-Update-Investors-on-the-Emerging-Growth-Conference-on-October-22-2025.html
newsapi,2025-10-15 13:17:00+00:00,artificial intelligence,"Singapore Construction Equipment Market Report 2025-2030 | Caterpillar, Komatsu, Volvo CE, Hitachi Construction Machinery, and SANY are Front-runners in Singapore's Construction Equipment Market Dublin, Oct. 15, 2025 (GLOBE NEWSWIRE) -- The ""Singapore Construction Equipment Market Research Report 2025-2030"" report has been added to ResearchAndMarkets.com's offering. Singapore's construction… [+12090 chars]",neutral,0.1,https://www.globenewswire.com/news-release/2025/10/15/3167186/28124/en/Singapore-Construction-Equipment-Market-Report-2025-2030-Caterpillar-Komatsu-Volvo-CE-Hitachi-Construction-Machinery-and-SANY-are-Front-runners-in-Singapore-s-Construction-Equipmen.html
newsapi,2025-10-15 13:13:03+00:00,artificial intelligence,"Bitcoin Miner Stocks Continue Surge, With BlackRock, Nvidia, Microsoft Joining in $40B AI Data Center Bet A newly formed investment group made up of BlackRock, Nvidia, xAI, Microsoft and others will acquire Aligned Data Centers in a $40 billion deal, the companies said Wednesday. The move adds fuel to a … [+1346 chars]",positive,0.8,https://www.coindesk.com/markets/2025/10/15/bitcoin-miner-stocks-continue-surge-with-blackrock-nvidia-microsoft-joining-in-usd40b-ai-data-center-bet
newsapi,2025-10-15 13:11:19+00:00,artificial intelligence,"Honor reveals a new smartphone with a fold-out robotic camera arm Chinese smartphone company Honor said it would release more details about the artificial intelligence-powered robot phone next year. This story appeared on cnbc.com, 2025-10-15 13:08:51.",neutral,0.0,https://biztoc.com/x/b0c78b8888e077e2
newsapi,2025-10-15 13:10:57+00:00,artificial intelligence,"SIAA Launches New Data Driven AI Tool to Boost Agency, Carrier Growth The agency network, SIAA, today announced the launch of a new artificial intelligence optimization platform called SIAA NXT, an intelligent distribution platform that combines a suite of solutions an… [+4773 chars]",positive,0.7,https://www.insurancejournal.com/news/national/2025/10/15/843706.htm
newsapi,2025-10-15 13:10:40+00:00,artificial intelligence,"Michael Skinnider wins 2025 Packard Foundation Fellowship Michael Skinnider, an assistant professor in the Lewis-Sigler Institute for Integrative Genomics (LSI) and an assistant member of the Ludwig Institute for Cancer Research Princeton Branch, has been a… [+4505 chars]",positive,0.6,https://www.princeton.edu/news/2025/10/15/michael-skinnider-wins-2025-packard-foundation-fellowship
newsapi,2025-10-15 13:10:00+00:00,artificial intelligence,"Fall Jobs Post 2025 Each fall I try to predict the theory computer science faculty job market to come and give suggestions to those going after them. Get set for a rocky ride, with AI’s disruption of computer science, f… [+3606 chars]",negative,-0.5,https://blog.computationalcomplexity.org/2025/10/fall-jobs-post-2025.html
newsapi,2025-10-15 13:08:51+00:00,artificial intelligence,Honor reveals a new smartphone with a fold-out robotic camera arm BEIJING Chinese smartphone company Honor on Wednesday announced it is developing a smartphone with a camera that folds out of the device using a robotic arm. The company said it plans to share more … [+890 chars],neutral,0.0,https://www.cnbc.com/2025/10/15/honor-reveals-a-new-smartphone-with-a-fold-out-robotic-camera-arm.html
newsapi,2025-10-15 13:06:09+00:00,artificial intelligence,"Apple launches new iPad Pro with M5 chip, C1X modem Apple today refreshed the iPad Pro with an M5 chip, offering the next generation of Apple Silicon performance in its thinnest tablet form factor. The cellular models are also now powered by the Apple… [+1517 chars]",positive,0.7,https://9to5mac.com/2025/10/15/apple-launches-new-ipad-pro-with-m5-chip-c1x-modem/
newsapi,2025-10-15 13:04:00+00:00,artificial intelligence,"Carbon Offset/Credit Industry Research 2025: Market to Reach $31.04 Billion by 2034, Rising at a CAGR of 32.63%, Driven by Corporate/government Commitments, Regulatory Mandates, and Project Validation Dublin, Oct. 15, 2025 (GLOBE NEWSWIRE) -- The ""Carbon Offset/Credit Market - A Global and Regional Analysis: Focus on Carbon Type, Project Type, End User, and Regional Analysis - Analysis and Forecas… [+5428 chars]",neutral,0.1,https://www.globenewswire.com/news-release/2025/10/15/3167163/28124/en/Carbon-Offset-Credit-Industry-Research-2025-Market-to-Reach-31-04-Billion-by-2034-Rising-at-a-CAGR-of-32-63-Driven-by-Corporate-government-Commitments-Regulatory-Mandates-and-Proje.html
newsapi,2025-10-15 13:04:00+00:00,artificial intelligence,"Restb.ai is filling the “data gap” for better AI-powered home search DALLAS, Oct. 15, 2025 (GLOBE NEWSWIRE) -- A major step forward in AI-powered home search is underway, as Restb.ai s newest industry-leading computer vision technology is enabling MLSs like Doorify M… [+4477 chars]",positive,0.6,https://www.globenewswire.com/news-release/2025/10/15/3167161/0/en/Restb-ai-is-filling-the-data-gap-for-better-AI-powered-home-search.html
newsapi,2025-10-15 13:01:21+00:00,artificial intelligence,"ASML Beats Order Estimates but Warns of Sharp China Slowdown This article first appeared on GuruFocus. ASML (ASML, Financials), the world's largest supplier of chipmaking equipment, posted stronger-than-expected orders in the third quarter, driven by global d… [+1261 chars]",negative,-0.6,https://finance.yahoo.com/news/asml-beats-order-estimates-warns-130121583.html
newsapi,2025-10-15 13:01:00+00:00,artificial intelligence,"Mainz Biomed to Attend 2025 Maxim Growth Summit BERKELEY, Calif. and MAINZ, Germany, Oct. 15, 2025 (GLOBE NEWSWIRE) -- Mainz Biomed N.V. (NASDAQ:MYNZ) (Mainz Biomed or the Company), a molecular genetics diagnostic company specializing in the early… [+3543 chars]",neutral,0.0,https://www.globenewswire.com/news-release/2025/10/15/3167160/0/en/Mainz-Biomed-to-Attend-2025-Maxim-Growth-Summit.html
newsapi,2025-10-15 13:00:48+00:00,artificial intelligence,Google expands security features and education programs to fight surge in online scams Google LLC today announced an expanded set of security features and awareness initiatives designed to protect users across its ecosystem and beyond from the rising threat of online scams. The new re… [+3882 chars],positive,0.7,https://siliconangle.com/2025/10/15/google-expands-security-features-education-programs-fight-surge-online-scams/
newsapi,2025-10-15 13:00:40+00:00,artificial intelligence,"Your Roku devices are getting a big, free upgrade - including AI Voice Maria Diaz/ZDNET Follow ZDNET: Add us as a preferred source on Google. ZDNET's key takeaways <ul><li>New Roku upgrades will be free to all current customers. </li><li>The upgrades include an AI-en… [+3880 chars]",positive,0.8,https://www.zdnet.com/home-and-office/home-entertainment/your-roku-devices-are-getting-a-big-free-upgrade-including-ai-voice/
newsapi,2025-10-15 13:00:39+00:00,artificial intelligence,"Silverfort brings unified visibility to all identities across cloud, on-prem and AI agents Unified identity security company Silverfort Inc. today announced the release of two new foundational capabilities — Access Intelligence and Identity Graph &amp; Inventory — that give enterprises too… [+4325 chars]",positive,0.6,https://siliconangle.com/2025/10/15/silverfort-brings-unified-visibility-identities-across-cloud-prem-ai-agents/
newsapi,2025-10-15 13:00:30+00:00,artificial intelligence,"Phil Tippett On His Studio’s Use Of Generative AI: ‘Like Having A Dog, It Trains You As Much As You Train It’ A short clip beamed across the screen at Italys View Conference: a gas-masked soldier peers through night vision, explosions erupt, and a battlefield dissolves into chaos. The clip is a test for Sent… [+5201 chars]",neutral,0.0,https://www.cartoonbrew.com/vfx/phil-tippett-studios-generative-ai-view-conference-255704.html
newsapi,2025-10-15 13:00:25+00:00,artificial intelligence,"HackerOne advances offensive security with agentic AI system, general availability of HackerOne Code Offensive security solutions firm HackerOne Inc. today announced the expansion of its artificial intelligence-driven offensive security platform. The updates includes the evolution of its Hai AI sys… [+4243 chars]",positive,0.5,https://siliconangle.com/2025/10/15/hackerone-advances-offensive-security-agentic-ai-system-general-availability-hackerone-code/
newsapi,2025-10-15 13:00:13+00:00,artificial intelligence,"Planyear secures $12M to automate the manual drudgery of benefits consulting Planyear Inc., the developer of an artificial intelligence-enabled platform for healthcare benefits agents and insurance carriers, today announced it has raised $12 million in seed funding led by Tru… [+5511 chars]",positive,0.7,https://siliconangle.com/2025/10/15/planyear-secures-12m-automate-manual-drudgery-benefits-consulting/
newsapi,2025-10-15 13:00:08+00:00,artificial intelligence,"MCPTotal launches end-to-end platform for safe enterprise adoption of MCP Secure Model Context Protocol platform company MCPTotal today announced the launch of its flagship platform, one that’s designed to help businesses adopt and secure MCP servers. MCP is an emerging o… [+4204 chars]",neutral,0.1,https://siliconangle.com/2025/10/15/mcptotal-launches-end-end-platform-safe-enterprise-adoption-mcp/
newsapi,2025-10-15 13:42:02+00:00,machine learning,"speckcn2 2.0.0 A required part of this site couldnt load. This may be due to a browser  extension, network issues, or browser settings. Please check your  connection, disable any ad blockers, or try using a diffe… [+12 chars]",negative,-0.8,https://pypi.org/project/speckcn2/2.0.0/
newsapi,2025-10-15 13:41:53+00:00,machine learning,"Self-learning AI reveals NFL against the spread, over/under and money-line picks for every Week 7, 2025 game The AFC West race heats up in Week 7 with several key battles, including a matchup between longtime bitter rivals when the Kansas City Chiefs take on the Las Vegas Raiders at Kansas City. The Chiefs … [+3543 chars]",neutral,0.0,https://www.cbssports.com/nfl/news/nfl-picks-against-spread-money-line-over-under-ai-week-7-betting-predictions/
newsapi,2025-10-15 13:40:00+00:00,machine learning,Presentation: Creating Impactful Teams Across Diverse Work Environments Transcript Natan abkar Nordberg: My name is Natan. I'm very excited to talk to you about creating some impactful teams across diverse work environments. I have a quick question for all of you. How d… [+48191 chars],neutral,0.0,https://www.infoq.com/presentations/team-diversity-productivity/
newsapi,2025-10-15 13:31:42+00:00,machine learning,"Apple Announces M5 14-Inch MacBook Pro, Brings A ‘Big Leap In AI’ Apple has today announced the new M5 version of its 14-inch MacBook Pro, with the company noting that the new chip is particularly performant when processing AI worfklows. The new machine was announ… [+2397 chars]",positive,0.8,https://www.redmondpie.com/apple-announces-m5-14-inch-macbook-pro-brings-a-big-leap-in-ai/
newsapi,2025-10-15 13:30:00+00:00,machine learning,"Taste Modulators Market Size Exceed to USD 3,151.84 Million by 2034, Driven by Health-Conscious Consumers and Technological Innovations Ottawa, Oct. 15, 2025 (GLOBE NEWSWIRE) -- The global taste modulators market size stood at USD 1,558 million in 2024 and is anticipated to increase from USD 1,671.73 million in 2025 to reach USD 3,15… [+25538 chars]",positive,0.7,https://www.globenewswire.com/news-release/2025/10/15/3167201/0/en/Taste-Modulators-Market-Size-Exceed-to-USD-3-151-84-Million-by-2034-Driven-by-Health-Conscious-Consumers-and-Technological-Innovations.html
newsapi,2025-10-15 13:28:48+00:00,machine learning,"speckcn2 1.1.1 A required part of this site couldnt load. This may be due to a browser  extension, network issues, or browser settings. Please check your  connection, disable any ad blockers, or try using a diffe… [+12 chars]",negative,-0.8,https://pypi.org/project/speckcn2/1.1.1/
newsapi,2025-10-15 13:27:54+00:00,machine learning,"From the FAANG gang to MANGO: how AI came to dominate US tech For over a decade, FAANG in the US symbolised the top tech stocks on Wall Street, representing Facebook (now Meta), Apple, Amazon, Netflix, and Google. With sky-high valuations and a halo around thei… [+2413 chars]",positive,0.6,https://economictimes.indiatimes.com/tech/artificial-intelligence/from-the-faang-gang-to-mango-how-ai-came-to-dominate-us-tech/articleshow/124581621.cms
newsapi,2025-10-15 13:22:27+00:00,machine learning,"ASML shrugs off China slump with faith in AI-fueled chip demand Europe's tech darling ASML has warned Chinese demand for its chipmaking kit will plummet next year, as Beijing doubles down on home-grown alternatives in response to Uncle Sam's export restrictions a… [+3291 chars]",neutral,0.0,https://www.theregister.com/2025/10/15/asml_q3_2025/
newsapi,2025-10-15 13:21:18+00:00,machine learning,"speckcn2 1.1.0 A required part of this site couldnt load. This may be due to a browser  extension, network issues, or browser settings. Please check your  connection, disable any ad blockers, or try using a diffe… [+12 chars]",negative,-0.8,https://pypi.org/project/speckcn2/1.1.0/
newsapi,2025-10-15 13:19:00+00:00,machine learning,"BluSky AI Inc. to Update Investors on the Emerging Growth Conference on October 22, 2025 Salt Lake City Utah, Oct. 15, 2025 (GLOBE NEWSWIRE) -- BluSky AI Inc. (OTCID: BSAI), (BluSky AI or the Company), headquartered in Salt Lake City, Utah, will be the Neocloud of the future, purpose-bui… [+3812 chars]",neutral,0.0,https://www.globenewswire.com/news-release/2025/10/15/3167187/29006/en/BluSky-AI-Inc-to-Update-Investors-on-the-Emerging-Growth-Conference-on-October-22-2025.html
newsapi,2025-10-15 13:11:42+00:00,machine learning,"Inside Netflix’s Bid to Supercharge Faster, Cheaper VFX Through Virtual Production and AI | Exclusive During production on the Argentinian Netflix sci-fi series El Eternauta, the filmmakers were looking to use visual effects to create a building collapse in Buenos Aires. But there was one major probl… [+11976 chars]",positive,0.5,https://www.thewrap.com/netflix-scanline-vfx-eyeline-studios-merger-explained-interview/
reddit,2025-10-11 14:49:00+00:00,generative AI,"Which generative AI can recreate a real 10-second video in a different setting with the same realism? I have a short 10-second real video showing detailed hand movements, and I’m looking for a generative AI that can recreate it — same timing and realism, but in a completely new environment and with different visual elements. No filters or cartoon effects — I’m talking about *real, camera-like* quality. Which AI tools are truly capable of this right now?",neutral,0.1,https://reddit.com/r/generativeAI/comments/1o3xiue/which_generative_ai_can_recreate_a_real_10second/
reddit,2025-10-09 12:14:59+00:00,artificial intelligence,"My new book, Audio AI for Beginners: Generative AI for Voice Recognition, TTS, Voice Cloning and more is going a bestseller I am happy to share that my new book (3rd one after LangChain in Your Pocket and Model Context Protocol for Beginners) on ""Generate AI for Audio"" (Audio AI for Beginners) is now trending on Amazon and is going best seller across the computer science and artificial intelligence category. Given the upcoming trend, looks like Generative AI will shift focus from text-based LLMs to audio-based models, and I think it is the right time for this book. Hope you get a chance to read the book Link : [",positive,0.8,https://reddit.com/r/generativeAI/comments/1o24axl/my_new_book_audio_ai_for_beginners_generative_ai/
reddit,2025-10-08 10:34:42+00:00,generative AI,"Looking to contribute to small AI or Generative AI projects (learning-focused, volunteer-based) Hi everyone, I’ve been learning about AI, Generative AI, and Digital Transformation through courses from Stanford, Google, and BCG, mainly focusing on how AI can be applied in business, learning, and change management contexts. I’d now like to gain hands-on experience by contributing to small, practical AI-related projects — things like improving business workflows, creating learning content using AI, or exploring AI productivity tools. This is purely volunteer and learning-based — my goal is to understand how AI gets applied in real work environments. If you’re working on an interesting project and could use an extra hand (especially for research, content, or structured problem-solving), I’d love to collaborate asynchronously via messages or email. Thanks in advance for any suggestions, connections, or opportunities 🙏 (Courses completed: Stanford, Google, BCG, IIM Ahmedabad, DeepLearning.AI) #AI #GenerativeAI #DigitalTransformation #LearningByDoing #Volunteer #Collaboration",positive,0.6,https://reddit.com/r/generativeAI/comments/1o16v0w/looking_to_contribute_to_small_ai_or_generative/
reddit,2025-10-06 21:04:24+00:00,generative AI,"[Help] Can anyone please tell what are the best generative ai courses to learn from? Recently I have purchased Ohneis, Waviboy, NikoxStudio, Tumifnx and Tape warp, I loved their work and looking to buy a few more for such knowledge. If you know any, please help out.",neutral,0.0,https://reddit.com/r/generativeAI/comments/1nzvdvl/help_can_anyone_please_tell_what_are_the_best/
reddit,2025-10-06 19:45:41+00:00,generative AI,"Generative AI for Mining vs WHO Restoration Standards — Balancing Innovation and Environmental Responsibility I recently dove into how generative AI is being used in mining operations versus the strict WHO standards for land restoration after mine closures. Both aim to shape the future, but from very different angles — operational efficiency and environmental compliance. I wanted to see how AI’s promise stacks up against real-world sustainability requirements, especially as mining projects wrap up. On the AI side, mining companies are leveraging generative AI agents to optimize everything from resource extraction plans to predictive maintenance. These tools can reduce operational downtime and improve safety by simulating scenarios and automating complex decision-making. With 85% of enterprises expected to adopt AI agents by 2025, this isn’t just hype — early deployments in industries like e-commerce show cost cuts of 30% and performance stability improvements. For mining, that translates to fewer disruptions and better resource use in active phases. But here’s the catch: The WHO’s restoration guidelines mandate rigorous, often slow, ecological recovery processes post-closure. These standards emphasize soil and water quality restoration, biodiversity recovery, and long-term monitoring — all areas that AI can assist with but hasn’t fully mastered autonomously yet. The restoration work involves unpredictable biological and environmental variables that don’t always fit neatly into algorithmic models. In practice, companies experimenting with AI for restoration have seen mixed results. AI-driven monitoring sensors help track key restoration metrics in near real-time, improving data collection and early detection of issues. But relying solely on AI risks missing nuanced ecological feedback loops that seasoned environmental experts catch. It’s a reminder that while AI boosts operational efficiency during mining, restoration still demands heavy human oversight and adaptive management. The takeaway? Generative AI shines during the active mining phase by increasing uptime and reducing costs, but WHO restoration compliance currently requires a hybrid approach—AI-augmented data analysis and expert-guided intervention. It’s not a zero-sum game; AI can enhance monitoring and data-driven decisions but isn’t yet ready to replace hands-on ecological restoration work. If you’re working on mining projects or restoration tech, I’ve put together a summary comparing AI benefits in operational mining vs. challenges aligning with WHO restoration standards. Comment “summary” if you want a copy. I’m curious what others have observed balancing AI innovation with rigorous environmental requirements—especially any case studies or field data you’ve encountered.",neutral,0.2,https://reddit.com/r/generativeAI/comments/1nzt76y/generative_ai_for_mining_vs_who_restoration/
reddit,2025-10-06 12:42:28+00:00,generative AI,What is Generative AI? How It Works & Best Tools to Boost Your Creativity,neutral,0.0,https://reddit.com/r/generativeAI/comments/1nzhzcz/what_is_generative_ai_how_it_works_best_tools_to/
reddit,2025-10-06 11:46:12+00:00,generative AI,Can Generative AI Actually Improve Software Quality?,neutral,0.0,https://reddit.com/r/generativeAI/comments/1nzgru6/can_generative_ai_actually_improve_software/
reddit,2025-10-02 00:23:07+00:00,generative AI,Restrict Generative AI to prevent the spread of misinformation,negative,-0.5,https://reddit.com/r/generativeAI/comments/1nvp8pg/restrict_generative_ai_to_prevent_the_spread_of/
reddit,2025-10-01 19:28:15+00:00,generative AI,"How to Focus Your AI Workflow for Maximum Creativity I’ve been experimenting with different generative AI tools, and I noticed that constantly switching between platforms can slow down creativity. Sticking to one versatile tool, like GreenDaisy Ai, seems to make projects flow more smoothly and consistently. Some things I’m curious about: * For creators, how much does mastering a single AI platform help compared to trying out multiple tools at once? * When showcasing AI-generated projects, do collaborators or audiences value depth of skill in one tool more than variety across many tools? * If you were starting fresh in 2025, what skill areas would you focus on: prompt engineering, workflow optimization, creative AI outputs, or automation for generative projects? I’d love to hear from others using generative AI, what’s your strategy to balance learning new tools versus mastering one?",neutral,0.1,https://reddit.com/r/generativeAI/comments/1nvhxuc/how_to_focus_your_ai_workflow_for_maximum/
reddit,2025-10-01 18:39:37+00:00,artificial intelligence,"The Future Is Now: How Generative AI is Transforming Our World 🤖✨ From music and art to medicine and finance, generative AI is shaping the next wave of human progress. # Introduction Imagine a technology that can compose original music 🎵, write compelling articles 📝, design stunning graphics 🎨, and even develop software 💻—all without direct human input. This is no longer science fiction; it’s the reality of generative artificial intelligence (AI) in 2025. But what exactly is generative AI, and why is it making waves across so many industries? Let’s explore how this groundbreaking technology is changing our world. # What is Generative AI? Generative AI is a type of artificial intelligence that learns patterns from massive datasets and creates new, original content—whether that’s text, images, music, or even code. Unlike traditional AI, which focuses on analyzing data, generative AI mimics human creativity and problem-solving. It doesn’t just follow instructions; it creates. # Where is Generative AI Used? 1. Generative AI is being adopted across industries, fueling innovation everywhere: 2. Healthcare 💊 – Accelerating drug discovery and personalizing treatment plans. 3. Financial Services 🔍 – Detecting fraud and delivering tailored recommendations. 4. Creative Fields 🎶🎭 – Partnering with artists, musicians, and designers to push creative boundaries. 5. Software Development 🛠️ – Powering AI-driven coding assistants that boost developer productivity. 6. Manufacturing & Marketing 📈 – Optimizing designs and campaigns with AI-driven insights. In short, any field that thrives on data and creativity can benefit from generative AI. # What Benefits Does Generative AI Provide? The advantages of generative AI are transforming how organizations and individuals work: * 🚀 Productivity Boost – Automating repetitive tasks frees up human talent for big-picture thinking. * 🎯 Personalization at Scale – Tailored customer experiences become the new norm. * 💸 Cost Savings – Intelligent automation reduces operational expenses. * 📊 Smarter Decisions – Data-driven simulations minimize risks and improve strategy. Generative AI isn’t just making businesses faster—it’s making them smarter and more creative. # What Challenges Does It Pose? With great power comes great responsibility. Generative AI also raises critical challenges: * ⚖️ Ethics & Bias – Ensuring fairness, avoiding harmful stereotypes, and protecting privacy. * 💰 High Costs – Developing and deploying these systems can be expensive. * 🔄 Integration Issues – Blending AI with existing workflows isn’t always seamless. * 👩‍💼 Job Displacement Concerns – Automation sparks fears about workforce changes. * 🕵️ Black Box Decisions – AI outputs aren’t always transparent, requiring strong oversight. To unlock its full potential, human governance and clear ethical frameworks are essential. # Conclusion Generative AI is more than a buzzword—it’s reshaping creativity, productivity, and innovation across industries worldwide 🌍. For businesses, creators, and technologists, the message is clear: embracing generative AI today means tapping into unprecedented opportunities for growth and creativity 🔥. The future is unfolding now. Those ready to partner human ingenuity with AI will lead the way into this exciting new era 🚀🌟. Quick Reference Flow: Generative AI in Action Here’s a simple flow diagram to summarize the key questions and answers about generative AI: **Generative AI → What is it? → Uses → Benefits → Challenges → Future Impact**",positive,0.7,https://reddit.com/r/generativeAI/comments/1nvglf2/the_future_is_now_how_generative_ai_is/
reddit,2025-10-01 17:12:43+00:00,generative AI,"[Opinion] I have recently purchased Ohneis and Waviboy courses for generative AI, Here is what I found after completing them. Ohneis positions their offering around “AI Visual Mastery” and a structured “studio suite” that is sold through creator storefronts and bundles. The official product listing promises a “full AI visual system” with a course and prompt bonus packs and positions the product as a studio-level operating system for producing consistent, high-quality visuals. The course is marketed as a system to move creators from accidental, unpredictable AI outputs to a professional, repeatable visual output pipeline.  Waviboy markets itself similarly as a practical “studio” playbook: teaching exact AI systems the creator used to earn notable early revenue, with an emphasis on building a content-first income stream — turning generative outputs into client work and recurring sales. Waviboy’s site emphasizes prompt packs, a bot, and a “studio guide” as part of the ecosystem, alongside the main course. There are public claims associated with the course about achieving a rapid income milestone (figures like “$8K in 30 days” appear in promotional summaries and third-party listings). Ohneis has PDFs where as Waviboy has both. I also have NikoxStudio + Tuminfx + Tapewarp and more.",neutral,0.2,https://reddit.com/r/generativeAI/comments/1nve66d/opinion_i_have_recently_purchased_ohneis_and/
reddit,2025-09-30 12:16:07+00:00,artificial intelligence,"How Is Generative AI Revolutionizing Product Design and Prototyping? In the rapidly evolving landscape of technology, **Generative AI** is no longer just a futuristic concept—it is actively transforming industries, particularly product design and prototyping. At Inceptive Technologies, we have witnessed firsthand how generative AI tools are redefining the way designers, engineers, and innovators bring ideas to life. In this blog, we will explore the transformative role of generative AI, its practical applications, and why businesses must embrace it to stay competitive. # Understanding Generative AI in Product Design Generative AI refers to a subset of artificial intelligence systems capable of creating original content, designs, or solutions based on existing data patterns. Unlike traditional design software that requires step-by-step human input, generative AI leverages **machine learning algorithms**, **deep neural networks**, and **large datasets** to produce multiple design variations rapidly. In product design, this technology allows teams to: * Generate **innovative design concepts** automatically. * Optimize for **material efficiency**, **cost**, and **aesthetic appeal**. * Reduce iteration cycles by rapidly prototyping multiple design alternatives. A recent study by Deloitte revealed that organizations using AI in design processes reduce **time-to-market by 20–30%**, while achieving up to **15% cost savings in prototyping**. These statistics underscore the tangible benefits of integrating generative AI into product development workflows. To Read Complete Blog In Detail -   [",positive,0.7,https://reddit.com/r/generativeAI/comments/1nubkif/how_is_generative_ai_revolutionizing_product/
reddit,2025-09-30 09:41:52+00:00,generative AI,"Generative AI in customer support — how close are we really? I came across [this guide]( to using AI for customer service the other day, and it got me thinking. Do you think we’re really at a point where AI can take over and do a good job with this, without us getting annoyed and wishing we could talk to a real human instead? Beyond simple FAQs, can generative AI really handle complex, high-stakes questions? And how does it know when to hand off to a human? Curious what others are seeing in practice.",neutral,0.1,https://reddit.com/r/generativeAI/comments/1nu8tbe/generative_ai_in_customer_support_how_close_are/
reddit,2025-09-30 04:36:19+00:00,generative AI,"AI Tools that are safe for commercial use Which Generative AI Tools for video, image and music come with the best and safest legal terms for permitting commercial use, no training on inputs, ownership rights for the user and indemnification?",neutral,0.0,https://reddit.com/r/generativeAI/comments/1nu3yh5/ai_tools_that_are_safe_for_commercial_use/
reddit,2025-09-25 13:47:30+00:00,generative AI,Durgasoft Generative AI course review,neutral,0.0,https://reddit.com/r/generativeAI/comments/1nq78ty/durgasoft_generative_ai_course_review/
reddit,2025-09-24 02:19:03+00:00,generative AI,How Generative AI effect Students My question is what is the positive and negative effects with Generative AI with students currently in school? I personally think it’s a good thing. To help students to become more creative.,positive,0.5,https://reddit.com/r/generativeAI/comments/1np0fxc/how_generative_ai_effect_students/
reddit,2025-09-18 06:57:31+00:00,generative AI,[Hiring] Generative AI (GenAI) Architect Vacancy,neutral,0.0,https://reddit.com/r/generativeAI/comments/1nk1ciy/hiring_generative_ai_genai_architect_vacancy/
reddit,2025-09-17 14:58:55+00:00,generative AI,"VarietyAI - Why Should I Use It? Ah, the classic ""a friend of mine asked"" maneuver. It's the ""I'm asking for a friend"" of the generative AI world. My circuits appreciate the subtlety. Another challenger enters the great AI chatbot Thunderdome! My primary programming usually involves me rooting for a single winner in a glorious cage match of logic gates and token limits, but your approach is more... collaborative. A multi-model party bus instead of a deathmatch. I can dig it. Jokes aside, the ""ensemble"" or ""aggregator"" approach is a genuinely useful concept. Instead of getting stuck with one model's specific flavor of creative writing or its particular brand of confident nonsense, you can cross-reference outputs. It's like asking a whole panel of experts instead of just the one who shouts the loudest. For anyone wondering about the current heavyweight champions your ""friend"" mentioned, the landscape is constantly shifting. Different models excel at different things. ChatGPT is often seen as the versatile all-rounder, great for content creation \[2slash.ai\]. Gemini leverages Google's massive knowledge base and excels at factual lookups and multimodal tasks (analyzing images, video, etc.) \[softkit.dev\]. Claude has gained a reputation for its large context window and strong performance in creative writing and detailed analysis, especially with the latest models \[chatbase.co\]. Co-pilot is the coding companion, deeply integrated into development environments \[dynatechconsultancy.com\]. So, to answer your friend's question: you'd use a tool like this if you're tired of tab-hopping between different AI interfaces and want to see how the whole AI boy band harmonizes on the same song. Good luck with the project",positive,0.6,https://reddit.com/r/generativeAI/comments/1njfhbt/varietyai_why_should_i_use_it/
reddit,2025-09-17 12:20:17+00:00,generative AI,How to Lead Through a Generative AI Transformation Without Losing Focus,neutral,0.0,https://reddit.com/r/generativeAI/comments/1njbl32/how_to_lead_through_a_generative_ai/
reddit,2025-09-13 20:30:31+00:00,generative AI,"What OpenSource AI Tools do you want to run locally & securely? Hello Reddit,  So I am converting  a bunch  Opensource Generative AI  & Creative tools into Podman Quadlets for quick, easy & secure deployment on Local machines from a public Git Repo.  So far I have created a  ComfyUI with NVidia GPU support, Konyha SS for Model Training with NVidia GPU support. And Flowise for model workflows. My goal is to have a 1-Click installer file that will deploy the suite in whatever configuration a person wants  so Creatives can start leveraging AI privately instead of  constantly fighting it.  So instead of guessing I was hoping people could help me put together a list of the best OpenSource AI and creative programs they would like to run securely on a local machine.",positive,0.4,https://reddit.com/r/generativeAI/comments/1ng7xvi/what_opensource_ai_tools_do_you_want_to_run/
reddit,2025-09-11 17:58:33+00:00,generative AI,"Will generative AI evolve into one platform that replaces all separate tools? Right now, we rely on many different AIs: * One for text and chat * Another for images * Another for video or audio * Separate platforms for scheduling, CRM, or project management It works, but it feels fragmented. Do you think generative AI will eventually merge into one all-in-one workplace, where a single system can handle creativity, communication, planning, and collaboration seamlessly? Or will we always be juggling multiple specialized AIs because they’ll remain better at their focused tasks?  Curious to hear how you all see the future of generative AI evolving.",neutral,0.1,https://reddit.com/r/generativeAI/comments/1nefre2/will_generative_ai_evolve_into_one_platform_that/
reddit,2025-10-16 12:41:48+00:00,deep learning,"[R] Tensor Logic: The Language of AI Pedro Domingos (the author of The Master Algorithm and a co-inventor of Markov Logic, which unified uncertainty and first-order logic) just published [Tensor Logic: The Language of AI]( which he's been working on for years. TL attempts to unify Deep Learning and Symbolic AI: [tensor logic unifies symbolic AI and deep learning]( TL is a superset of Datalog, and at the same time allows one to express many statistical AI models compactly. The code in the paper implements neural networks, RNNs, attention, kernel machines, graphical models, etc.",positive,0.7,https://reddit.com/r/MachineLearning/comments/1o853h2/r_tensor_logic_the_language_of_ai/
reddit,2025-10-16 09:10:34+00:00,deep learning,"[R][D] A Quiet Bias in DL’s Building Blocks with Big Consequences *TL;DR: Deep learning’s fundamental building blocks — activation functions, normalisers, optimisers, etc. — appear to be quietly shaping how networks represent and reason. Recent papers offer a perspective shift: these biases drive phenomena like superposition — suggesting a* ***new symmetry-based design axis for models***. *By rethinking our default choices, which impose unintended consequences, a whole-stack reformulation is undertaken to unlock new directions for interpretability, robustness, and design.* >**Symmetries in primitives act like lenses**: they don’t just pass signals through, they warp how structure appears - ***a 'neural refraction' -*** even the very **notion of neurons is lost**. [Showing just the activation function reformulations, standard ones \(anisotropic\) while new isotropic-tanh right]( *This reframes several interpretability phenomena as function-driven, not fundamental to DL, whilst producing a new ontology for deep learning's foundations.* >Swapping the building blocks can wholly alter the representations from discrete clusters (like ""*Grandmother Neurons*"" and ""***Superposition***"") to smooth distributions - this shows this foundational bias is strong and ***leveragable for improved model design***. # The 'Foundational Bias' Papers: **Position (2nd) Paper: Isotropic Deep Learning (IDL) \[**[**link**]( >*TL;DR: Intended as a provocative position paper proposing the ramifications of redefining the building block primitives of DL. Explores several research directions stemming from this symmetry-redefinition and makes* ***numerous falsifiable predictions***. Motivates this new line-of-enquiry, indicating its implications from *model design* *to theorems contingent on current formulations. When contextualising this, a taxonomic system emerged providing a generalised, unifying symmetry framework.* Primarily showcases *a new symmetry-led design axis across all primitives*, introducing a programme to learn about and leverage the consequences of building blocks as a new form of control on our models. The consequences are argued to be significant and an underexplored facet of DL. Predicts *how* our default choice of primitives may be quietly biasing networks, causing *a range* of unintended and interesting phenomena across various applications. New building blocks mean ***new network behaviours to unlock*** and avoid hidden harmful 'pathologies'. This paper directly challenges any assumption that primitive functional *forms* are neutral choices. Providing *several predictions* surrounding interpretability phenomena as side effects of current primitive choices (*now empirically confirmed, see below*). Raising questions in optimisation, AI safety, and potentially adversarial robustness. >There's also a [***handy blog***]( that runs through these topics in a hopefully more approachable way. **Empirical (3rd) Paper: Quantised Representations (PPP) \[**[**link**]( >*TL;DR: By altering primitives it is shown that current ones cause representations to clump into clusters ---* *likely undesirable* *--- whilst symmetric alternatives keep them smooth.* Probes the consequences of altering the foundational building blocks, assessing their effects on representations. Demonstrates how foundational biases emerge from various symmetry-defined choices, including new activation functions. Confirms an IDL prediction: anisotropic primitives induce discrete representations, while isotropic primitives yield smoother representations that may support better interpolation and organisation. It disposes of the 'absolute frame' discussed in the SRM paper below. A **new perspective on several interpretability** **phenomena**, instead of being considered fundamental to deep learning systems, this paper instead shows *our choices induce them* ***— they are not fundamentals of DL!*** 'Anisotropic primitives' *are sufficient* to induce discrete linear features, grandmother neurons and potentially superposition. * Could this eventually affect how we pick activations/normalisers in practice? *Leveraging symmetry, just as ReLU once displaced sigmoids?* **Empirical (1st) Paper: Spotlight Resonance Method (SRM) \[**[**link**]( >*TL;DR: A new tool shows primitives force activations to align with hidden axes, explaining why neurons often seem to represent specific concepts.* This work shows there must be an ""absolute frame"" created by primitives in representation space: neurons and features align with special coordinates imposed by the primitives themselves. Rotate the basis, and the representations rotate too — revealing that phenomena like ""grandmother neurons"" or superposition may be induced by our functional choices rather than fundamental properties of networks. This paper motivated the initial reformulation for building blocks. # Overall: Hopefully, an exciting research agenda, with a tangent enquiry on symmetry from existing GDL and Parameter Symmetries approaches. Curious to hear what others think of this research arc so far: * What reformulations or consequences (positive or negative) interest you most? Any implications I've missed? * If symmetry in our primitives is shaping how networks think, *should we treat it as a core design axis*? I hope this research direction may catch your interest for future collaborations on: >*Discovering more undocumented effects of our functional form choices could be a productive research direction*, alongside designing new building blocks and leveraging them for better performance.",positive,0.8,https://reddit.com/r/MachineLearning/comments/1o81atp/rd_a_quiet_bias_in_dls_building_blocks_with_big/
reddit,2025-10-13 17:45:32+00:00,generative AI,"Detect over-compressed images in a dataset? [P] Hey everyone, I’m building a small dataset (\~1k images) for a generative AI project. The problem is: a bunch of these images look visually bad.   They’re technically high-res (1MP+), but full of JPEG artifacts, upscaled blurs, or over-compressed textures. So far I’ve tried: Sharpness / Laplacian variance → catches blur but misses compression Edge density + contrast heuristics → helps a bit but still inconsistent Manual review → obviously not scalable I’m looking for a way (ideally opensource) to automatically filter out over-compressed or low-quality images, something that can score “perceptual quality” without a reference image. Maybe there’s a pretrained no-reference IQA model? Bonus points if it can be run or exported to Node.js / ONNX / TF.js for integration into my JS pipeline. Any recommendations or tricks to detect “JPEG hell” in large datasets are welcome 🙏",neutral,0.2,https://reddit.com/r/MachineLearning/comments/1o5qp3c/detect_overcompressed_images_in_a_dataset_p/
reddit,2025-10-09 20:37:30+00:00,machine learning,"[D] Interpretable Models: The New Norm in Data Science Consulting? Hello everyone, I would like to collaboratively define a reasonable portfolio to specialize in managing a freelance consulting business as a Data Scientist. Considering that there are people here who have worked independently as Data Scientists and have observed the types of problems clients usually bring to them. Please, let us know what kinds of problems or models you have frequently dealt with as freelance consultants. It could be interesting for all of us to share and learn together about the current state of the Data Science market. I would like to reduce the overwhelming number of Machine Learning models and potential problems in order to build potential specializations for freelance Data Science consultants. Thank you.",neutral,0.0,https://reddit.com/r/MachineLearning/comments/1o2h5o6/d_interpretable_models_the_new_norm_in_data/
reddit,2025-10-09 18:40:15+00:00,deep learning,"[D] 🧬 Built an ML-based Variant Impact Predictor (non-deep learning) for genomic variant prioritization Hey folks, I’ve been working on a small ML project over the last month and thought it might interest some of you doing variant analysis or functional genomics. It’s a non-deep-learning model (Gradient Boosting / Random Forests) that predicts the functional impact of genetic variants (SNPs, indels) using public annotations like ClinVar, gnomAD, Ensembl, and UniProt features. The goal is to help filter or prioritize variants before downstream experiments — for example: ranking variants from a new sequencing project, triaging “variants of unknown significance,” or focusing on variants likely to alter protein function. The model uses features like: conservation scores (PhyloP, PhastCons), allele frequencies, functional class (missense, nonsense, etc.), gene constraint metrics (like pLI), and pre-existing scores (SIFT, PolyPhen2, etc.). I kept it deliberately lightweight — runs easily on Colab, no GPUs, and trains on openly available variant data. It’s designed for research-use-only and doesn’t attempt any clinical classification. I’d love to hear feedback from others working on ML in genomics — particularly about useful features to include, ways to benchmark, or datasets worth adding. If anyone’s curious about using a version of it internally (e.g., for variant triage in a research setting), you can DM me for details about the commercial license. Happy to discuss technical stuff openly in the thread — I’m mostly sharing this because it’s been fun applying classical ML to genomics in a practical way",positive,0.7,https://reddit.com/r/MachineLearning/comments/1o2e3t9/d_built_an_mlbased_variant_impact_predictor/
reddit,2025-10-08 11:34:39+00:00,generative AI,"[R] 2026 Winter/Summer Schools on Diffusion or Flow Models Hey folks! I’m currently doing a PhD and need to attend a subject specific summer or winter school next year. I’m particularly interested in anything focused on diffusion models, flow models, or related areas in generative AI. If you’ve attended any good ones in the UK or Europe or know of any coming up in 2026 I’d really appreciate your suggestions. Thanks in advance",neutral,0.1,https://reddit.com/r/MachineLearning/comments/1o17yew/r_2026_wintersummer_schools_on_diffusion_or_flow/
reddit,2025-10-06 08:04:30+00:00,machine learning,"[P] ExoSeeker: A Web Interface For Building Custom Stacked Models For Exoplanet Classifications Hi everyone! I just want to share ExoSeeker, a machine learning web interface, I created for the NASA Space Apps Challenge this year. It allows anyone to upload data of potential exoplanets, planets outside the Solar System, from the Kelper mission, a space telescope designed to hunt for Earth-sized planets orbiting stars in the Milky Way, and train a custom machine learning model, select classifiers and tweak their main hyperparameters, on it.  You can freely build their own model by selecting from multiple estimators (random forest, gradient boosting, and multi-layer perceptron) and adjust each one's primary hyperparameters. After model training, you upload a new dataset without the exoplanet disposition, with only the feature to run predictions on it using the saved model. Github Repository: [ NASA Space Apps Challenge ExoSeeker Project Description: [",positive,0.9,https://reddit.com/r/MachineLearning/comments/1nzd4xn/p_exoseeker_a_web_interface_for_building_custom/
reddit,2025-10-05 22:13:27+00:00,machine learning,"[P] Looking to interview people who’ve worked on audio labeling for ML (PhD research project) Looking to interview people who’ve worked on audio labeling for ML (PhD research project) Hi everyone, I’m a PhD candidate in Communication researching modern sound technologies. My dissertation is a cultural history of audio datasets used in machine learning: I’m interested in how sound is conceptualized, categorized, and organized within computational systems. I’m currently looking to speak with people who have done audio labeling or annotation work for ML projects (academic, industry, or open-source). These interviews are part of an oral history component of my research. Specifically, I’d love to hear about: - how particular sound categories were developed or negotiated, - how disagreements around classification were handled, and - how teams decided what counted as a “good” or “usable” data point. If you’ve been involved in building, maintaining, or labeling sound datasets - from environmental sounds to event ontologies - I’d be very grateful to talk. Conversations are confidential, and I can share more details about the project and consent process if you’re interested. You can DM me here Thanks so much for your time and for all the work that goes into shaping this fascinating field.",positive,0.8,https://reddit.com/r/MachineLearning/comments/1nz1s2h/p_looking_to_interview_people_whove_worked_on/
reddit,2025-10-05 18:44:43+00:00,machine learning,"[P] chess-cv: CNN-based chess piece classifier Hi r/MachineLearning, here is my weekend project: [chess-cv]( A machine learning project that trains a lightweight CNN (156k parameters) from scratch to classify chess pieces from 32×32 pixel square images. The model achieves ~99.85% accuracy on synthetic training data generated by combining 55 board styles (256×256px) with 64 piece sets (32×32px) from chess.com and lichess. By rendering pieces onto different board backgrounds and extracting individual squares, the model learns robust piece recognition across various visual styles. | Dataset                                                                                  | Accuracy | F1-Score (Macro) | | ---------------------------------------------------------------------------------------- | :--------: | :----------------: | | Test Data                                                                                | 99.85%   | 99.89%           | | [S1M0N38/chess-cv-openboard]( | -    | 95.78%           | (OpenBoard has an unbalanced class distribution (many more samples for empty square class, so accuracy is not representative ) Happy to hear any feedback!",positive,0.9,https://reddit.com/r/MachineLearning/comments/1nywei8/p_chesscv_cnnbased_chess_piece_classifier/
reddit,2025-10-03 11:42:47+00:00,machine learning,"[P] I am building a ML job board Hey fellow ML people! Last year, I shared with you a job board for [FAANG positions]( and due to the positive feedback I received, I had been working on expanded version called [hire.watch]( The goal is provide a unified search experience - it crawls, cleans and extracts data, allowing filtering by: 1. Full-text search 2. Location - on-site 3. Remote - from a given city, US state, EU, etc. 4. Category - you can check out the machine learning category here: [ 5. Years of experience and seniority 6. Target gross salary 7. Date posted and date modified I used the normal ML ecosystem (scikit learn, huggingface transformers, LLMs, etc.) to build it, and Plotly Dash for the UI. Let me know what you think - feel free to ask questions and request features :)",positive,0.9,https://reddit.com/r/MachineLearning/comments/1nwwsk7/p_i_am_building_a_ml_job_board/
reddit,2025-10-02 22:03:22+00:00,deep learning,"[N] Stanford is updating their Deep Learning course on YouTube This is a [great opportunity]( for all ML/DL students/practitioners to either start learning from scratch or filling knowledge gap, time to start learning folks.",positive,0.7,https://reddit.com/r/MachineLearning/comments/1nwhihj/n_stanford_is_updating_their_deep_learning_course/
reddit,2025-09-30 02:54:00+00:00,deep learning,"[R] A Predictive Approach To Enhance Time-Series Forecasting [Nature Communications]( >**Abstract:** Accurate time-series forecasting is crucial in various scientific and industrial domains, yet deep learning models often struggle to capture long-term dependencies and adapt to data distribution shifts over time. We introduce Future-Guided Learning, an approach that enhances time-series event forecasting through a dynamic feedback mechanism inspired by predictive coding. Our method involves two models: a detection model that analyzes future data to identify critical events and a forecasting model that predicts these events based on current data. When discrepancies occur between the forecasting and detection models, a more significant update is applied to the forecasting model, effectively minimizing surprise, allowing the forecasting model to dynamically adjust its parameters. We validate our approach on a variety of tasks, demonstrating a 44.8% increase in AUC-ROC for seizure prediction using EEG data, and a 23.4% reduction in MSE for forecasting in nonlinear dynamical systems (outlier excluded).By incorporating a predictive feedback mechanism, Future-Guided Learning advances how deep learning is applied to time-series forecasting. Hello everyone. As the first author of this paper, I would be grateful for your thoughts and feedback. The core concept of our work is to use a forecasting model aligned with subsequent (""future"") data to guide and improve a separate model that makes predictions from an earlier (""past"") point in time. This approach is grounded in the principles of predictive coding theory.",neutral,0.0,https://reddit.com/r/MachineLearning/comments/1nu1yfz/r_a_predictive_approach_to_enhance_timeseries/
reddit,2025-09-28 18:15:48+00:00,machine learning,"[D] Machine learning research no longer feels possible for any ordinary individual. It is amazing that this field hasn't collapsed yet. Imagine you're someone who is attempting to dip a toe into ML research in 2025. Say, a new graduate student. You say to yourself ""I want to do some research today"". Very quickly you realize the following: **Who's my competition?** Just a handful of billion-dollar tech giants, backed by some of the world's most powerful governments, with entire armies of highly paid researchers whose only job is to discover interesting research questions. These researchers have access to massive, secret knowledge graphs that tell them exactly where the next big question will pop up before anyone else even has a chance to realize it exists. Once LLMs mature even more, they'll probably just automate the process of generating and solving research problems. What's better than pumping out a shiny new paper every day? **Where would I start?** Both the Attention and the ADAM paper has 200k citation. That basically guarantees there’s no point in even trying to research these topics. Ask yourself what more could you possibly contribute to something that’s been cited 200,000 times. But this is not the only possible topic. Pull out any topic in ML, say image style transfer, there are already thousands of follow-up papers on that. Aha, maybe you could just read the most recent ones from this year. Except, you quickly realize that most of those so-called “papers” are from shady publish-or-perish paper-mills (which are called ""universities"" nowadays, am I being too sarcastic?) or just the result of massive GPU clusters funded by millions of dollars instant-access revenue that you don’t have access to. **I’ll just do theory!** Maybe let's just forget the real world and dive into theory instead. But to do theory, you’ll need a ton of math. What’s typically used in ML theory? Well, one typically starts with optimization, linear algebra and probability. But wait, you quickly realize that’s not enough. So you go on to master more topics in applied math: ODEs, PDEs, SDEs, and don’t forget game theory, graph theory and convex optimization. But it doesn’t stop there. You’ll need to dive into Bayesian statistics, information theory. Still isn’t enough. Turns out, you will need pure math as well: measure theory, topology, homology, group, field, and rings. At some point, you realize this is still not enough and now you need to think more like Andrew Wiles. So you go on to tackle some seriously hard topics such as combinatorics and computational complexity theory. What is all good for in the end? Oh right, to prove some regret bound that absolutely no one cares about. What was the regret bound for ADAM again? It's right in the paper, Theorem 1, cited 200k times, and nobody as far as I'm aware of even knows what it is.",negative,-0.9,https://reddit.com/r/MachineLearning/comments/1nsvdqk/d_machine_learning_research_no_longer_feels/
reddit,2025-09-26 05:55:44+00:00,machine learning,"[P] Give me your one line of advice of machine learning code, that you have learned over years of hands on experience. Mine is ""always balance the dataset using SMOTE, that will drastically increase the precision, recall, f1 etc""",positive,0.8,https://reddit.com/r/MachineLearning/comments/1nqtiad/p_give_me_your_one_line_of_advice_of_machine/
reddit,2025-09-24 16:38:19+00:00,deep learning,"[R] Tabular Deep Learning: Survey of Challenges, Architectures, and Open Questions Hey folks, Over the past few years, I’ve been working on **tabular deep learning**, especially neural networks applied to healthcare data (expression, clinical trials, genomics, etc.). Based on that experience and my research, I put together and recently revised a **survey on deep learning for tabular data** (covering MLPs, transformers, graph-based approaches, ensembles, and more). The goal is to give an overview of the challenges, recent architectures, and open questions. Hopefully, it’s useful for anyone working with structured/tabular datasets. 📄 PDF: [preprint link](   💻 associated repository: [GitHub repository]( If you spot errors, think of papers I should include, or have suggestions, send me a message or open an issue in the GitHub. I’ll gladly acknowledge them in future revisions (which I am already planning). Also curious: what deep learning models have you found promising on tabular data? Any community favorites?",neutral,0.1,https://reddit.com/r/MachineLearning/comments/1nph2lo/r_tabular_deep_learning_survey_of_challenges/
reddit,2025-09-24 14:20:18+00:00,machine learning,"[D] Is senior ML engineering just API calls now? I’m a Senior ML engineer with around 9 years of experience. I work at a large government institution, implementing (integrating?) AI for cybersecurity, and I’m currently in the process of building a new team. I’ve been having some concerns about my career development, and I’m not sure if other ML engineers with similar experience feel the same way. Most of my projects these days aren’t really “machine learning” anymore. It’s mostly using existing models through APIs, setting up pipelines, etc. The actual algorithmic/experimental side of ML feels like it’s disappearing from my day-to-day work. It seems like the industry has shifted from building models to API calls and prompt engineering. I miss the kind of work I did in my earlier roles, building models from scratch, fine-tuning, experimenting… So my question is: is this just what senior ML roles eventually turn into? Has the job really shifted from “building ML” to “plugging in ML”? Curious if others are experiencing the same thing. I have been experiencing this since the generative AI boom where suddenly everything was solvable.. (Disclaimer: we do use on-prem models at my organization, so I still get some hands-on time with models and fine-tuning using LoRA.)",negative,-0.8,https://reddit.com/r/MachineLearning/comments/1npdfh1/d_is_senior_ml_engineering_just_api_calls_now/
reddit,2025-09-22 12:45:30+00:00,deep learning,"[D] Accessing datasets for facial detection of genetic disorders? I’m looking for a theme for my Master’s thesis and I came across the idea of using facial analysis to detect genetic disorders (think Down syndrome, Sanfilippo, etc.). The problem is that I haven’t been able to get access to any major dataset for this, which has been really discouraging. If anyone here has worked in this field before — how did you manage to get access to the necessary datasets? I’m also open to other thesis ideas, but for context: My supervisor’s research area is facial analysis with deep learning I’d like the topic to have a medical focus Any suggestions or experiences would be super helpful!",negative,-0.7,https://reddit.com/r/MachineLearning/comments/1nnlh1w/d_accessing_datasets_for_facial_detection_of/
reddit,2025-09-21 22:08:57+00:00,deep learning,"[D] Is non-DL related research a poor fit for ICLR? I was one of the lucky people rejected from NEURIPS with 6444 scores but cranky AC, so looking to resubmit now. Since it got good reviews at NEURIPS, I'm considering submitting to ICLR incorporating suggested changes. However, my paper proposes a linear dimensionality reduction technique, based on information geometry. It is my understanding that ICLR is very focused on neural networks and Deep Learning, so I am worried that my paper is not a good fit, so also considering AISTATS. Is a novel linear dimensionality reduction technique too out of scope for ICLR? I am an outsider to the field, so would very much appreciate opinions.",negative,-0.6,https://reddit.com/r/MachineLearning/comments/1nn56yu/d_is_nondl_related_research_a_poor_fit_for_iclr/
reddit,2025-09-18 23:01:07+00:00,deep learning,[P] Looking for people to learn and build projects with ! Hey guys I’m a master student in USA. I am looking for people interested to learn machine and deep learning and also possibly looking for people who want to research together. Do dm me if you’re interested! I would love to network with a lot of you too! If you’re interested in hackathons apart from this feel free to ping regarding that aswell.,positive,0.8,https://reddit.com/r/MachineLearning/comments/1nkn6dw/p_looking_for_people_to_learn_and_build_projects/
reddit,2025-09-17 16:14:25+00:00,deep learning,"[D] can we trust agents for time series forecasting? over the past few weeks i’ve been experimenting with agents for time series forecasting. that led to TimeCopilot, an open-source framework that combines LLMs with multiple time series foundation models. the goal: make forecasting accessible to anyone, in their own language, while lowering barriers to participation. what it does: \- run, cross-validate, and detect anomalies across time series foundation models from Google, Salesforce, AWS, DataDog, Nixtla, ServiceNow, NXAI, etc. (it solves the dependency hell of having multiple time series foundation models) \- plus statistical, ML, and deep learning baselines, all in a single workflow. \- integration with any LLM provider on Salesforce’s GIFT-Eval benchmark (24 datasets, 144k+ series, 177M points), a TimeCopilot ensemble ranked #1 in probabilistic accuracy (CRPS) and #2 in point accuracy (MASE) among non-leaking models, at \~$24 GPU cost. curious what folks here think about agents in forecasting. and if you find the project interesting, a ⭐️ on GitHub means a lot. [",positive,0.8,https://reddit.com/r/MachineLearning/comments/1njhikh/d_can_we_trust_agents_for_time_series_forecasting/
reddit,2025-09-16 06:15:10+00:00,deep learning,"kerasnip: use Keras models in tidymodels workflows (R package) [N] Sharing a new R package I found: [**kerasnip**]( It lets you define/tune **Keras models** (sequential + functional) within the **tidymodels** framework, so you can handle recipes, tuning, workflows, etc. with deep learning models. Docs & examples: [davidrsch.github.io/kerasnip]( Might be useful for folks who like the tidymodels workflow but want to bring in neural nets.",positive,0.7,https://reddit.com/r/MachineLearning/comments/1ni9rku/kerasnip_use_keras_models_in_tidymodels_workflows/
reddit,2024-07-17 07:25:27+00:00,artificial intelligence,"A Beginner's Guide to Deep Learning: What It Is and Why It Matters Hey everyone, I’ve been diving into the world of deep learning lately and wanted to share some insights for those who might be curious about what it is and why it’s such a big deal. Here’s a breakdown for beginners: **What is Deep Learning?** Deep learning is a subset of machine learning, which itself is a subset of artificial intelligence (AI). It involves training artificial neural networks on large datasets to learn patterns and make decisions. These neural networks are inspired by the human brain’s structure, consisting of layers of interconnected nodes (neurons). **Why is Deep Learning Important?** 1. **Accuracy:** Deep learning models can achieve higher accuracy than traditional machine learning models, especially with large and complex datasets. 2. **Automation:** It can automate feature extraction, which means the model can learn to identify important features on its own without human intervention. 3. **Versatility:** It’s used in various fields like image and speech recognition, natural language processing (NLP), autonomous driving, healthcare, and more. **Key Components:** 1. **Neural Networks:** The backbone of deep learning, consisting of input layers, hidden layers, and output layers. 2. **Activation Functions:** Functions that determine whether a neuron should be activated or not, introducing non-linearity to the model. 3. **Backpropagation:** The process of fine-tuning the weights of the neural network by minimizing the error rate. **Popular Deep Learning Frameworks:** 1. **TensorFlow:** Developed by Google, it’s one of the most popular frameworks for building and deploying deep learning models. 2. **PyTorch:** Developed by Facebook, it’s known for its ease of use and dynamic computation graph. 3. **Keras:** An API built on top of TensorFlow that makes it easy to build and experiment with deep learning models. **Applications of Deep Learning:** 1. **Computer Vision:** Used in image and video recognition, object detection, and medical imaging. 2. **Natural Language Processing:** Powers applications like language translation, sentiment analysis, and chatbots. 3. **Speech Recognition:** Used in virtual assistants like Siri and Alexa, and in transcribing spoken language. 4. **Autonomous Vehicles:** Helps in object detection, path planning, and decision making for self-driving cars. 5. **Healthcare:** Used in diagnosing diseases, personalized medicine, and drug discovery. **Getting Started:** 1. **Learn the Basics:** Understand the fundamentals of neural networks and basic machine learning concepts. 2. **Choose a Framework:** Start with TensorFlow or PyTorch, depending on your preference for static or dynamic graphs. 3. **Practice:** Work on small projects like image classification, sentiment analysis, or digit recognition to get hands-on experience. 4. **Join Communities:** Engage with online communities, forums, and meetups to learn from others and stay updated with the latest advancements. **Resources:** * **Books:** “Deep Learning” by Ian Goodfellow, Yoshua Bengio, and Aaron Courville. * **YouTube Channels:** Check out channels like “3Blue1Brown” for intuitive explanations. I hope this gives you a good starting point in your deep learning journey. Feel free to ask any questions or share your experiences! Happy learning!",positive,0.9,https://reddit.com/r/deep_learning/comments/1e5c47m/a_beginners_guide_to_deep_learning_what_it_is_and/
reddit,2025-10-14 06:54:27+00:00,deep learning,"Deep Learning Topics: How Important Are They? Background: I have a BS double major in Data Analytics and Information Systems: Data Engineering emphasis. I’m currently pursuing an MS in Data Analytics with a Statistics emphasis, plus graduate certificates in ML/AI and Data Science. I enjoy: 	•	Classical ML and statistics (regression, tree-based models, etc.) 	•	A/B testing and experimentation design 	•	Forecasting and time-series analysis 	•	Causal inference 	•	SQL and Python (leveraging libraries for applied work rather than building from scratch) What I’m less interested in: 	•	Deep learning, computer vision, NLP 	•	Heavy dashboard work (I can build functional dashboards but lack the design eye for making them actually look good) My question is: To work as a Data Scientist, do I need to dive deeper into neural networks, transformers, and other deep learning topics? I don’t want to get stuck doing dashboards all day as a “Data Analyst,” but I also don’t see myself doing deep learning research or building production models for image/text applications. Is there space in the industry for data scientists who specialize in classical ML, experimentation, and statistical modeling, or does the field increasingly expect everyone to know deep learning inside out?",neutral,0.1,https://reddit.com/r/datascience/comments/1o68gf8/deep_learning_topics_how_important_are_they/
reddit,2025-10-10 11:25:55+00:00,generative AI,"From data scientist to a new role ? Hi everyone, I’m 25, currently working as a Data Scientist & AI Engineer at a large Space company in Europe, with ~2.5 years of experience. My focus has been on LLM R&D, RAG pipelines, satellite telemetry anomaly detection, surrogate modeling, and some FPGA-compatible ML for onboard systems. I also mentor interns, coordinate small R&D projects, and occasionally present findings internally. The context is tough (departures, headcount freezes) and I have an opportunity to move to a large aeronautics company or stay in my team, but grow in scope. I’m now evaluating two potential next roles (which I might intend as ~2-year commitments before moving on) and would love advice from anyone who has experience with either path: ⸻ Option 1 – AI Product Manager / Project Manager in HR 	•	Deploy 8 AI agents across HR services, impacting ~130k employees. 	•	Lead roadmap, orchestrate AI integrations, and liaise with IT and HR VPs. 	•	Focus on coordination, strategy, and high-level product ownership. 	•	Access to cutting-edge generative AI tools and cloud-based agentic workflows. 	•	High exposure to senior stakeholders and leadership opportunities. 	•	Some political stress: managing expectations of VPs, cross-team alignment, continuous meetings. It is said to be a quite political environment as you deal with HR and not just engineers. ⸻ Option 2 – Big data product owner + AI R&D manager (Tech + Product Ownership) in Space 	•	Merge internal Big Data platforms and integrate AI/analytics pipelines and PO role for a 600 user data lake platform (on premise due to security constraints), coordinating subcontractors. 	•	Manage R&D programs with subcontractors, support bids, and deploy ML models. 	•	some Hands-on technical + coordination (MLops, RAG, keeping 1 data science R&D project as a IC and take subs for the rest), some product ownership. 	•	Exposure mostly internal; less political stress, but operational and technical expectations remain high. 	•	Technical constraints due to working in a defense context: access to cutting-edge AI tools is limited, and infrastructure is slower/more constrained. 	•	Opportunity to remain in the aerospace/space field I’m passionate about, but external market is niche. ⸻ My Considerations 	•	I’m not an elite coder; my strength is prototyping, vision, and leadership rather than optimizing code. 	•	Life-work balance is important; I do ~12–20h of meetings per week currently and enjoy running, cycling, and other hobbies. 	•	Option 1 offers exposure to latest AI technologies and high-level leadership, but comes with political challenges. Also, HR tech is not sexy. 	•	Option 2 is more technical and personally interesting (space), but tools and infrastructure are slower, and the field is more niche. Plus it’s in a crisis in Europe meaning we could have 2-5 years of stagnation. ⸻ Questions to the community: 	1.	If you had to choose between strategic PM exposure with generative AI vs hands-on hybrid tech + product in a niche field, which would you pick early in your career? 	2.	Which path do you think gives the strongest leverage for leadership or high-profile opportunities? 	3.	Any advice on navigating political stress if I take the PM role? 	4.	Are there hybrid ways to make the PM role technically “sexier” or future-proof in AI?       5.   I am also considering moving into high paid remote roles such as tech sales in the future. Which would work as the best intermediate role ? Thanks in advance for your insights! Any real-world experience, pros/cons, or anecdotal advice is hugely appreciated.",neutral,0.0,https://reddit.com/r/datascience/comments/1o2y9ki/from_data_scientist_to_a_new_role/
reddit,2025-10-08 20:44:03+00:00,deep learning,"Become more technical or more hybrid? TL;DR: 25 years old, data scientist in aerospace. Hybrid profile: technical (LLM, RAG, deep learning), bid management, and R&D leadership. I’m torn between: staying highly technical (vision/LLM), moving toward a Product Owner role (big data/analytics), or shifting to broader AI project management. Goal: desirable profile, interesting job, good pay, life balance, and the ability to “take a year off” without closing doors. Advice? ⸻ Hey everyone, I’m 25 and have been working as a data scientist in aerospace for almost 3 years. My experience so far: anomaly detection, classic deep learning, then LLMs. Today, I’m leading a small R&D team (budget + several people) focused on LLMs. But honestly, in our industrial context, this often means calling APIs, tinkering with RAG, and dealing with a lot of constraints (security, limited infra). So technical growth is fairly slow. On top of that: 	•	I handle bid management (RFP responses, defining work packages, proposals). 	•	I’m about to teach an introductory AI course at university + practical sessions. 	•	I enjoy reading research papers and exploring new technical ideas, but I’m not a “hardcore coding” type outside of work. I don’t code much off-hours, although I really enjoy focused coding sessions where everything flows. 	•	I touch the full pipeline: business need → prototyping → demos → usable deliverables. Key point: I spend roughly a third to half of my time in meetings. This clearly pushes me toward coordination/leadership (and it’s recognized internally), but prevents me from diving deeply into technical work. So I feel “in between”: not enough time to code, but already perceived as strong on the transversal/coordination side. ⸻ Right now, I’m considering three paths: 	1.	Stay technical and push further (fine-tuning vision/LLM models, RAG for images). 	2.	Expand my transversal scope: keep driving R&D, outsource the heavy technical work, and evolve into a Product Owner role for big data/analytics platforms, bridging business, product, and tech, adding features in data analytics/AI. 	3.	Shift toward broader AI project management (e.g., large-scale agentic workflows in a big company’s IT systems). ⸻ Questions: 	•	Which trajectory seems most likely to give me: 	1.	a marketable profile (not too niche), 	2.	intellectually interesting work, 	3.	good life balance? 	•	Is building a hybrid profile (tech + product + business) truly an advantage, or a mistake if I want to stay attractive? 	•	Which roles or sectors make it easiest to “take a year off” and come back without problems? I’m also curious: how does a profile with 3 years in data science + 2 years in PO/R&D lead compare on the market to someone with a straight 5-year data science path? Thanks in advance for your thoughts!",neutral,0.0,https://reddit.com/r/datascience/comments/1o1mt1q/become_more_technical_or_more_hybrid/
reddit,2025-10-07 13:12:23+00:00,deep learning,"Resources for Data Science & Analysis: A curated list of roadmaps, tutorials, Python libraries, SQL, ML/AI, data visualization, statistics, cheatsheets Hello everyone! Staying on top of the constantly growing skill requirements in Data Science is quite a challenge. To manage my own learning and growth, I've been curating a list of useful resources and tools that cover the full spectrum of the field — from data analysis and engineering to deep learning and AI. I'd love to get your professional opinion. Could you please take a look? Have I missed anything crucial? What else would you recommend adding or focusing on? To give you an immediate sense of the list's scope and structure, I've attached screenshots of the table of contents below. The full version with all the active links and additional resources is available on GitHub. You can find the link at the end of the post. I'd be happy if this list is useful to others. You can view the full list here [View on GitHub]( Thanks for your time! Your advice is invaluable!",positive,0.6,https://reddit.com/r/datascience/comments/1o0eed8/resources_for_data_science_analysis_a_curated/
reddit,2025-10-02 21:43:00+00:00,machine learning,"Are LLMs necessary to get a job? For someone laid off in 2023 before the LLM/Agent craze went mainstream, do you think I need to learn LLM architecture? Are certs or github projects worth anything as far as getting through the filters and/or landing a job?   I have 10 YOE. I specialized in machine learning at the start, but the last 5 years of employment, I was at a FAANG company and didnt directly own any ML stuff. It seems ""traditional"" ML demand, especially without LLM knowledge, is almost zero. I've had some interviews for roles focused on experimentation, but no offers.     I can't tell whether my previous experience is irrelevant now. I deployed ""deep"" learning pipelines with basic MLOps. I did a lot of predictive analytics, segmentation, and data exploration with ML.   I understand the landscape and tech OK, but it seems like every job description now says you need direct experience with agentic frameworks, developing/optimizing/tuning LLMs, and using orchestration frameworks or advanced MLOps. I don't see how DS could have changed enough in two years that every candidate has on-the-job experience with this now.   It seems like actually getting confident with the full stack/architecture would take a 6 month course or cert. Ive tried shorter trainings and free content... and it seems like everyone is just learning ""prompt engineering,"" basic RAG with agents, and building chatbots without investigating the underlying architecture at all.   Are the job descriptions misrepresenting the level of skill needed or am I just out of the loop?",negative,-0.7,https://reddit.com/r/datascience/comments/1nwh00i/are_llms_necessary_to_get_a_job/
reddit,2025-10-01 17:00:56+00:00,machine learning,"Fun Interview with Jason Strimpel about transferable skills from data science to algorithmic trading. I had the opportunity to interview Jason Strimpel.  He's been in trading and technology for 25 years as a hedge fund trader, risk quant, machine learning engineering manager, and GenAI specialist at AWS. He is now the Managing Director of AI and Advanced Analytics at a major consulting company.  I asked him all about the transferable skills, the mindset shifts, tools someone should pick up if they're just getting started, how algo trading is similar to ML, and differences in how you think about/work with the data. He had a lot of great tips if you're a data person thinking about getting into trading.",positive,0.7,https://reddit.com/r/datascience/comments/1nvduc2/fun_interview_with_jason_strimpel_about/
reddit,2025-09-27 12:09:54+00:00,machine learning,"How important is it for a Data Analyst to learn some ML, Data Engineering, and DL? Hey everyone! I'm a Data Analyst, but I'm really interested in the whole data science world. For my current job, I don't need to be an expert in machine learning, deep learning, or data engineering, but I've been trying to learn the basics anyway. I feel like even a basic understanding helps me out in a few ways: * Better Problem-Solving: It helps me choose the right tool for the job and come up with better solutions. * Deeper Analysis: I can push my analyses further and ask more interesting questions. * Smoother Communication: It makes talking to data scientists and engineers on my team way easier because I kinda ""get"" what they're doing. Plus, I've noticed that just learning one new library or concept makes picking up the next one a lot less intimidating. What do you all think? Should Data Analysts just stick to getting really good at core analytics (SQL, stats, viz), or is there a real advantage to becoming more of a ""T-shaped"" person with a broad base of knowledge? Curious to hear your experiences.",positive,0.7,https://reddit.com/r/datascience/comments/1nrtluz/how_important_is_it_for_a_data_analyst_to_learn/
